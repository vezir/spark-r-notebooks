{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkR ve SparkSQL kullanımı\n",
    "\n",
    "[R ile Apache Spark a giriş, Hakan Sarıbıyık](https://github.com/vezir/spark-r-notebooks)\n",
    "\n",
    "Bu notebook ile SparkR ın kullanımına [SparkR dokümanlarında](http://spark.apache.org/docs/latest/sparkr.html) verildiği şekilde bakacağız. Veriyi SparkSQL dataFrame e aktaracağız, sonrasında schemaya bakacağız. \n",
    "\n",
    "Veri setimiz, *ABD - California da yol kazalarında yaralanmaları 2002-2010* [Road Traffic Injuries 2002-2010](http://www.healthdata.gov/dataset/road-traffic-injuries-2002-2010) ile ilgili verileri içeriyor.\n",
    "\n",
    "Bu veri setinde Kaliforniya'da yaşayan kişi ve mil başına olan trafik kazalarının yaya, otomobil, motorsiklet gibi kategorilerdeki istatistikleri, Kaliforniya'nın alt bölgeleri bazında verilmektedir. Veriyi doğrudan incelemek isterseniz [analiz için hazırlanmış sayfadan](https://cdph.data.ca.gov/Environment/Road-Traffic-Injuries-2002-2010/xmwz-xvsf) faydalanabilirsiniz. Var olan alanların neler olduğu ile ilgili bir [excel doküman](https://cdph.data.ca.gov/api/views/xmwz-xvsf/files/vFZ2-VvAdPb_6aOkATlLb19r3PpHHYGEgns1EH3kAQs?download=true&filename=RoadTrafficInjuries_DD.xlsx) da mevcuttur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL context i yaratmak\n",
    "\n",
    "Bu ve sonraki notebooklarda veriyi dataFrame aktarmak için öncelikle bir SparkSQL context e ihtiyacımız olacak. Ayrıca, SPARK_HOME gibi temel değişkenlere uygun değerleri atamamız da gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spark ın kurulduğu dizin\n",
    "Sys.setenv(SPARK_HOME=\"/usr/local/spark\")\n",
    "# SparkR ın kurulduğu dizinden yüklenmesi için gerekiyor\n",
    ".libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\"), .libPaths()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparkR kütüphanesini yükleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘SparkR’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    colnames, colnames<-, intersect, rank, rbind, sample, subset,\n",
      "    summary, table, transform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(SparkR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark ı kullanabilmemiz için bir SparkContext te ihtiyacımız var. Bunu Spark ın [sayfasında](http://spark.apache.org/docs/latest/sparkr.html#starting-up-sparkcontext-sqlcontext) anlatıldığı şekilde yapacak olursak sparkR.init komutunu kullanmamız gerekiyor. Burada master olarak Spark ın bulundugu makinanın IP sini yada lokalde ise *local* kelimesini kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /usr/local/spark/bin/spark-submit  --packages com.databricks:spark-csv_2.11:1.2.0 sparkr-shell /tmp/RtmpVzZfyG/backend_port9534a1e1961 \n"
     ]
    }
   ],
   "source": [
    "sc <- sparkR.init(master=\"local\", sparkPackages=\"com.databricks:spark-csv_2.11:1.2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu şekilde emrimizi bekleyen bir spark elde ettik. sparkPackages a koyduğumuz paket csv formatındaki dosyaları okumak için kullanılan bir paket. Artık dataFrame oluşturmak için gereken sparkSQL context i oluşturabiliriz. Çalıştırdığımız işlerin detay takibini standart olarak http://10.0.2.15:4040 adresinden browser yardımı ile yapabiliriz. Jupyter notebook un loglarından sizinkini görebilirisiniz. Artık sqlContext e geçebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL de data frame lerin yaratılması\n",
    "\n",
    "## CSV dosyanın okunması\n",
    "Databricks firmasının csv formatlı dosyalardan data frame oluşturmak için kullanıma sunduğu [paket](https://github.com/databricks/spark-csv) i kullanarak veriyi data frame e aktarıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file_path <- '/home/dsuser/shared'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_injuries_file_path <- file.path('','home','dsuser','shared','Road_Traffic_Injuries.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/home/dsuser/shared/Road_Traffic_Injuries.txt\"\n"
     ]
    }
   ],
   "source": [
    "print(traffic_injuries_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.000   0.000  19.541 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.time(\n",
    "    traffic_injuries_df <- read.df(sqlContext, \n",
    "                        paste('file:', traffic_injuries_file_path, sep=''), \n",
    "                        header='true', \n",
    "                        source = \"com.databricks.spark.csv\", \n",
    "                        inferSchema='true')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inferSchema='true' dediğimiz için dataFrame e aktarılırken veri yapısı otomatik olarak tespit edildi. Herhangi bir problem olup olmadığına bakalım. Bu noktada veri yapısını veren [excel dokümanını](https://cdph.data.ca.gov/api/views/xmwz-xvsf/files/vFZ2-VvAdPb_6aOkATlLb19r3PpHHYGEgns1EH3kAQs?download=true&filename=RoadTrafficInjuries_DD.xlsx)  kullanabiliriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ind_id: integer (nullable = true)\n",
      " |-- ind_definition: string (nullable = true)\n",
      " |-- reportyear: string (nullable = true)\n",
      " |-- race_eth_code: integer (nullable = true)\n",
      " |-- race_eth_name: string (nullable = true)\n",
      " |-- geotype: string (nullable = true)\n",
      " |-- geotypevalue: long (nullable = true)\n",
      " |-- geoname: string (nullable = true)\n",
      " |-- county_name: string (nullable = true)\n",
      " |-- county_fips: integer (nullable = true)\n",
      " |-- region_name: string (nullable = true)\n",
      " |-- region_code: integer (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- severity: string (nullable = true)\n",
      " |-- injuries: double (nullable = true)\n",
      " |-- totalpop: double (nullable = true)\n",
      " |-- poprate: double (nullable = true)\n",
      " |-- LL95CI_poprate: double (nullable = true)\n",
      " |-- UL95CI_poprate: double (nullable = true)\n",
      " |-- poprate_se: double (nullable = true)\n",
      " |-- poprate_rse: double (nullable = true)\n",
      " |-- CA_decile_pop: string (nullable = true)\n",
      " |-- CA_RR_poprate: double (nullable = true)\n",
      " |-- avmttotal: double (nullable = true)\n",
      " |-- avmtrate: double (nullable = true)\n",
      " |-- LL95CI_avmtrate: double (nullable = true)\n",
      " |-- UL95CI_avmtrate: double (nullable = true)\n",
      " |-- avmtrate_se: double (nullable = true)\n",
      " |-- avmtrate_rse: double (nullable = true)\n",
      " |-- CA_decile_avmt: string (nullable = true)\n",
      " |-- CA_RR_avmtrate: double (nullable = true)\n",
      " |-- groupquarters: double (nullable = true)\n",
      " |-- version: string (nullable = true)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "    0.0     0.0     0.1 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.time(\n",
    "    printSchema(traffic_injuries_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada eğer tipi yanlış belirlenmiş bir alan var ise düzeltebiliriz. İncelediğimizde aşağıdaki alanların dokümandaki tiplerine uymadıklarını görüyoruz. Örnek region_code schema da integer yapılmış ama dokümana göre string olmalı. Burada örnek olması açısından bunu düzeltelim.\n",
    "\n",
    "```\n",
    "geotypevalue : string\n",
    "county_fips : string\n",
    "region_code : string\n",
    "CA_decile_pop : numeric\n",
    "CA_decile_avmt : numeric\n",
    "version : datetime (10/10/2014 12:00:00 AM)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traffic_injuries_df$region_code <- cast(traffic_injuries_df$region_code, \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_code un string olduğunu kontrol edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ind_id: integer (nullable = true)\n",
      " |-- ind_definition: string (nullable = true)\n",
      " |-- reportyear: string (nullable = true)\n",
      " |-- race_eth_code: integer (nullable = true)\n",
      " |-- race_eth_name: string (nullable = true)\n",
      " |-- geotype: string (nullable = true)\n",
      " |-- geotypevalue: long (nullable = true)\n",
      " |-- geoname: string (nullable = true)\n",
      " |-- county_name: string (nullable = true)\n",
      " |-- county_fips: integer (nullable = true)\n",
      " |-- region_name: string (nullable = true)\n",
      " |-- region_code: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- severity: string (nullable = true)\n",
      " |-- injuries: double (nullable = true)\n",
      " |-- totalpop: double (nullable = true)\n",
      " |-- poprate: double (nullable = true)\n",
      " |-- LL95CI_poprate: double (nullable = true)\n",
      " |-- UL95CI_poprate: double (nullable = true)\n",
      " |-- poprate_se: double (nullable = true)\n",
      " |-- poprate_rse: double (nullable = true)\n",
      " |-- CA_decile_pop: string (nullable = true)\n",
      " |-- CA_RR_poprate: double (nullable = true)\n",
      " |-- avmttotal: double (nullable = true)\n",
      " |-- avmtrate: double (nullable = true)\n",
      " |-- LL95CI_avmtrate: double (nullable = true)\n",
      " |-- UL95CI_avmtrate: double (nullable = true)\n",
      " |-- avmtrate_se: double (nullable = true)\n",
      " |-- avmtrate_rse: double (nullable = true)\n",
      " |-- CA_decile_avmt: string (nullable = true)\n",
      " |-- CA_RR_avmtrate: double (nullable = true)\n",
      " |-- groupquarters: double (nullable = true)\n",
      " |-- version: string (nullable = true)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.020   0.004   0.040 "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.time(\n",
    "    printSchema(traffic_injuries_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>ind_id</th><th scope=col>ind_definition</th><th scope=col>reportyear</th><th scope=col>race_eth_code</th><th scope=col>race_eth_name</th><th scope=col>geotype</th><th scope=col>geotypevalue</th><th scope=col>geoname</th><th scope=col>county_name</th><th scope=col>county_fips</th><th scope=col>ellip.h</th><th scope=col>avmttotal</th><th scope=col>avmtrate</th><th scope=col>LL95CI_avmtrate</th><th scope=col>UL95CI_avmtrate</th><th scope=col>avmtrate_se</th><th scope=col>avmtrate_rse</th><th scope=col>CA_decile_avmt</th><th scope=col>CA_RR_avmtrate</th><th scope=col>groupquarters</th><th scope=col>version</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>326842416136</td><td>12.51062</td><td>12.12715</td><td>12.89408</td><td>0.1956456</td><td>1.563837</td><td></td><td>1</td><td>823151</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>326842416136</td><td>41.12991</td><td>40.43462</td><td>41.8252</td><td>0.3547396</td><td>0.8624857</td><td></td><td>1</td><td>823151</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>1214809885</td><td>69.9698</td><td>45.99164</td><td>93.94795</td><td>12.23375</td><td>17.48433</td><td></td><td>1</td><td>NA</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>1214809885</td><td>452.7457</td><td>325.3094</td><td>580.1821</td><td>65.01855</td><td>14.36094</td><td></td><td>1</td><td>NA</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td></td><td>NA</td><td>823151</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td></td><td>NA</td><td>823151</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllll}\n",
       "  & ind_id & ind_definition & reportyear & race_eth_code & race_eth_name & geotype & geotypevalue & geoname & county_name & county_fips & ellip.h & avmttotal & avmtrate & LL95CI_avmtrate & UL95CI_avmtrate & avmtrate_se & avmtrate_rse & CA_decile_avmt & CA_RR_avmtrate & groupquarters & version\\\\\n",
       "\\hline\n",
       "\t1 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & 326842416136 & 12.51062 & 12.12715 & 12.89408 & 0.1956456 & 1.563837 &  & 1 & 823151 & 10/10/2014 12:00:00 AM\\\\\n",
       "\t2 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & 326842416136 & 41.12991 & 40.43462 & 41.8252 & 0.3547396 & 0.8624857 &  & 1 & 823151 & 10/10/2014 12:00:00 AM\\\\\n",
       "\t3 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & 1214809885 & 69.9698 & 45.99164 & 93.94795 & 12.23375 & 17.48433 &  & 1 & NA & 10/10/2014 12:00:00 AM\\\\\n",
       "\t4 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & 1214809885 & 452.7457 & 325.3094 & 580.1821 & 65.01855 & 14.36094 &  & 1 & NA & 10/10/2014 12:00:00 AM\\\\\n",
       "\t5 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & NA & NA & NA & NA & NA & NA &  & NA & 823151 & 10/10/2014 12:00:00 AM\\\\\n",
       "\t6 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & NA & NA & NA & NA & NA & NA &  & NA & 823151 & 10/10/2014 12:00:00 AM\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  ind_id\n",
       "1    753\n",
       "2    753\n",
       "3    753\n",
       "4    753\n",
       "5    753\n",
       "6    753\n",
       "                                                                                                   ind_definition\n",
       "1 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "2 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "3 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "4 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "5 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "6 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "  reportyear race_eth_code race_eth_name geotype geotypevalue    geoname\n",
       "1       2002             9         Total      CA            6 California\n",
       "2       2002             9         Total      CA            6 California\n",
       "3       2002             9         Total      CA            6 California\n",
       "4       2002             9         Total      CA            6 California\n",
       "5       2002             9         Total      CA            6 California\n",
       "6       2002             9         Total      CA            6 California\n",
       "  county_name county_fips region_name region_code      mode      severity\n",
       "1                      NA                      NA All modes        Killed\n",
       "2                      NA                      NA All modes Severe Injury\n",
       "3                      NA                      NA Bicyclist        Killed\n",
       "4                      NA                      NA Bicyclist Severe Injury\n",
       "5                      NA                      NA       Bus        Killed\n",
       "6                      NA                      NA       Bus Severe Injury\n",
       "  injuries totalpop     poprate LL95CI_poprate UL95CI_poprate  poprate_se\n",
       "1     4089 34944563 11.70139114   11.342729435    12.06005285 0.182990668\n",
       "2    13443 34944563 38.46950383   37.819187649    39.11982000 0.331793967\n",
       "3       85 33493644  0.25377950    0.199828044     0.30773095 0.027526251\n",
       "4      550 33493644  1.64210262    1.504864419     1.77934082 0.070019491\n",
       "5        9 34944563  0.02575508    0.008928428     0.04258173 0.008585027\n",
       "6       22 34944563  0.06295686    0.036648863     0.08926486 0.013422448\n",
       "  poprate_rse CA_decile_pop CA_RR_poprate    avmttotal  avmtrate\n",
       "1   1.5638369                           1 326842416136  12.51062\n",
       "2   0.8624857                           1 326842416136  41.12991\n",
       "3  10.8465229                           1   1214809885  69.96980\n",
       "4   4.2640143                           1   1214809885 452.74574\n",
       "5  33.3333333                           1           NA        NA\n",
       "6  21.3200716                           1           NA        NA\n",
       "  LL95CI_avmtrate UL95CI_avmtrate avmtrate_se avmtrate_rse CA_decile_avmt\n",
       "1        12.12715        12.89408   0.1956456    1.5638369               \n",
       "2        40.43462        41.82520   0.3547396    0.8624857               \n",
       "3        45.99164        93.94795  12.2337519   17.4843326               \n",
       "4       325.30938       580.18210  65.0185515   14.3609416               \n",
       "5              NA              NA          NA           NA               \n",
       "6              NA              NA          NA           NA               \n",
       "  CA_RR_avmtrate groupquarters                version\n",
       "1              1        823151 10/10/2014 12:00:00 AM\n",
       "2              1        823151 10/10/2014 12:00:00 AM\n",
       "3              1            NA 10/10/2014 12:00:00 AM\n",
       "4              1            NA 10/10/2014 12:00:00 AM\n",
       "5             NA        823151 10/10/2014 12:00:00 AM\n",
       "6             NA        823151 10/10/2014 12:00:00 AM"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(traffic_injuries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Verinin satır sayısını öğrenelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "494226"
      ],
      "text/latex": [
       "494226"
      ],
      "text/markdown": [
       "494226"
      ],
      "text/plain": [
       "[1] 494226"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrow(traffic_injuries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bu noktada önemli bir konu *traffic_injuries_df* nin DataFrame nesnesi olarak SparkSQL de kullanılmasıdır.\n",
    "Fakat R daki data.frame lerin her kullanıldığı yerde kullanılamaz. SparkR için geliştirilen komutlar\n",
    "kapsamında DataFrame nesneleri kullanılabilir. Eğer normal R komutları kullanılacaksa R daki data.frame lere dönüştürülmelidir.\n",
    "SparkSQL dışında spark ın komutları kullanılacaksa [Resilient Distributed Dataset (RDD)](http://spark.apache.org/docs/latest/quick-start) ye çevrilmesi gerekir. Yani, aynı veriyi üç ayrı şekilde\n",
    "tutabiliyoruz. Bunu herzaman akılda tutmak gerekiyor.\n",
    "\n",
    "Örnek olarak *traffic_injuries_df* e *str* komutu ile baktığımızda;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal class 'DataFrame' [package \"SparkR\"] with 2 slots\n",
      "  ..@ env:<environment: 0x3b45b60> \n",
      "  ..@ sdf:Class 'jobj' <environment: 0x2b36e60> \n"
     ]
    }
   ],
   "source": [
    "str(traffic_injuries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada DataFrame nesnesi SparkSQL komutları ile işlem yapmamızı sağlıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_injuries_dfx <- filter(\n",
    "    traffic_injuries_df, \n",
    "   traffic_injuries_df$injuries >  13400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2"
      ],
      "text/latex": [
       "2"
      ],
      "text/markdown": [
       "2"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>ind_id</th><th scope=col>ind_definition</th><th scope=col>reportyear</th><th scope=col>race_eth_code</th><th scope=col>race_eth_name</th><th scope=col>geotype</th><th scope=col>geotypevalue</th><th scope=col>geoname</th><th scope=col>county_name</th><th scope=col>county_fips</th><th scope=col>ellip.h</th><th scope=col>avmttotal</th><th scope=col>avmtrate</th><th scope=col>LL95CI_avmtrate</th><th scope=col>UL95CI_avmtrate</th><th scope=col>avmtrate_se</th><th scope=col>avmtrate_rse</th><th scope=col>CA_decile_avmt</th><th scope=col>CA_RR_avmtrate</th><th scope=col>groupquarters</th><th scope=col>version</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>326842416136</td><td>41.12991</td><td>40.43462</td><td>41.8252</td><td>0.3547396</td><td>0.8624857</td><td></td><td>1</td><td>823151</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2004</td><td>9</td><td>Total</td><td>CA</td><td>6</td><td>California</td><td></td><td>NA</td><td>⋯</td><td>333917717425</td><td>40.66271</td><td>39.97875</td><td>41.34668</td><td>0.3489622</td><td>0.8581873</td><td></td><td>1</td><td>824661</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllll}\n",
       "  & ind_id & ind_definition & reportyear & race_eth_code & race_eth_name & geotype & geotypevalue & geoname & county_name & county_fips & ellip.h & avmttotal & avmtrate & LL95CI_avmtrate & UL95CI_avmtrate & avmtrate_se & avmtrate_rse & CA_decile_avmt & CA_RR_avmtrate & groupquarters & version\\\\\n",
       "\\hline\n",
       "\t1 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 6 & California &  & NA & ⋯ & 326842416136 & 41.12991 & 40.43462 & 41.8252 & 0.3547396 & 0.8624857 &  & 1 & 823151 & 10/10/2014 12:00:00 AM\\\\\n",
       "\t2 & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2004 & 9 & Total & CA & 6 & California &  & NA & ⋯ & 333917717425 & 40.66271 & 39.97875 & 41.34668 & 0.3489622 & 0.8581873 &  & 1 & 824661 & 10/10/2014 12:00:00 AM\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  ind_id\n",
       "1    753\n",
       "2    753\n",
       "                                                                                                   ind_definition\n",
       "1 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "2 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "  reportyear race_eth_code race_eth_name geotype geotypevalue    geoname\n",
       "1       2002             9         Total      CA            6 California\n",
       "2       2004             9         Total      CA            6 California\n",
       "  county_name county_fips region_name region_code      mode      severity\n",
       "1                      NA                      NA All modes Severe Injury\n",
       "2                      NA                      NA All modes Severe Injury\n",
       "  injuries totalpop  poprate LL95CI_poprate UL95CI_poprate poprate_se\n",
       "1    13443 34944563 38.46950       37.81919       39.11982  0.3317940\n",
       "2    13578 35720010 38.01231       37.37292       38.65169  0.3262168\n",
       "  poprate_rse CA_decile_pop CA_RR_poprate    avmttotal avmtrate LL95CI_avmtrate\n",
       "1   0.8624857                           1 326842416136 41.12991        40.43462\n",
       "2   0.8581873                           1 333917717425 40.66271        39.97875\n",
       "  UL95CI_avmtrate avmtrate_se avmtrate_rse CA_decile_avmt CA_RR_avmtrate\n",
       "1        41.82520   0.3547396    0.8624857                             1\n",
       "2        41.34668   0.3489622    0.8581873                             1\n",
       "  groupquarters                version\n",
       "1        823151 10/10/2014 12:00:00 AM\n",
       "2        824661 10/10/2014 12:00:00 AM"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows <- nrow(traffic_injuries_dfx)\n",
    "nrows\n",
    "head(traffic_injuries_dfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdide verinin genel istatistiklerine gözatalım. Önce komutun tanımına bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for describe {SparkR}\"><tr><td>describe {SparkR}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>summary</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Computes statistics for numeric columns.\n",
       "If no columns are given, this function computes statistics for all numerical columns.\n",
       "</p>\n",
       "<p>Returns the summary of a model produced by glm(), similarly to R's summary().\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "## S4 method for signature 'DataFrame,character'\n",
       "describe(x, col, ...)\n",
       "\n",
       "## S4 method for signature 'DataFrame,ANY'\n",
       "describe(x)\n",
       "\n",
       "## S4 method for signature 'DataFrame'\n",
       "summary(object, ...)\n",
       "\n",
       "describe(x, col, ...)\n",
       "\n",
       "summary(object, ...)\n",
       "\n",
       "## S4 method for signature 'PipelineModel'\n",
       "summary(object, ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>x</code></td>\n",
       "<td>\n",
       "<p>A DataFrame to be computed.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>col</code></td>\n",
       "<td>\n",
       "<p>A string of name</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Additional expressions</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>object</code></td>\n",
       "<td>\n",
       "<p>A fitted MLlib model</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A DataFrame\n",
       "</p>\n",
       "<p>a list with 'devianceResiduals' and 'coefficients' components for gaussian family\n",
       "or a list with 'coefficients' component for binomial family. <br />\n",
       "For gaussian family: the 'devianceResiduals' gives the min/max deviance residuals\n",
       "of the estimation, the 'coefficients' gives the estimated coefficients and their\n",
       "estimated standard errors, t values and p-values. (It only available when model\n",
       "fitted by normal solver.) <br />\n",
       "For binomial family: the 'coefficients' gives the estimated coefficients.\n",
       "See summary.glm for more information. <br />\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p>Other DataFrame functions: <code>$</code>,\n",
       "<code>$&lt;-</code>, <code>select</code>,\n",
       "<code>select</code>,\n",
       "<code>select,DataFrame,Column-method</code>,\n",
       "<code>select,DataFrame,list-method</code>,\n",
       "<code>selectExpr</code>; <code>DataFrame-class</code>,\n",
       "<code>dataFrame</code>, <code>groupedData</code>;\n",
       "<code>[</code>, <code>[</code>, <code>[[</code>,\n",
       "<code>subset</code>; <code>agg</code>,\n",
       "<code>agg</code>,\n",
       "<code>count,GroupedData-method</code>,\n",
       "<code>summarize</code>, <code>summarize</code>;\n",
       "<code>arrange</code>, <code>arrange</code>,\n",
       "<code>arrange</code>, <code>orderBy</code>,\n",
       "<code>orderBy</code>; <code>as.data.frame</code>,\n",
       "<code>as.data.frame,DataFrame-method</code>;\n",
       "<code>attach</code>,\n",
       "<code>attach,DataFrame-method</code>;\n",
       "<code>cache</code>; <code>collect</code>;\n",
       "<code>colnames</code>, <code>colnames</code>,\n",
       "<code>colnames&lt;-</code>, <code>colnames&lt;-</code>,\n",
       "<code>columns</code>, <code>names</code>,\n",
       "<code>names&lt;-</code>; <code>coltypes</code>,\n",
       "<code>coltypes</code>, <code>coltypes&lt;-</code>,\n",
       "<code>coltypes&lt;-</code>; <code>columns</code>,\n",
       "<code>dtypes</code>, <code>printSchema</code>,\n",
       "<code>schema</code>, <code>schema</code>;\n",
       "<code>count</code>, <code>nrow</code>;\n",
       "<code>dim</code>; <code>distinct</code>,\n",
       "<code>unique</code>; <code>dropna</code>,\n",
       "<code>dropna</code>, <code>fillna</code>,\n",
       "<code>fillna</code>, <code>na.omit</code>,\n",
       "<code>na.omit</code>; <code>dtypes</code>;\n",
       "<code>except</code>, <code>except</code>;\n",
       "<code>explain</code>, <code>explain</code>;\n",
       "<code>filter</code>, <code>filter</code>,\n",
       "<code>where</code>, <code>where</code>;\n",
       "<code>first</code>, <code>first</code>;\n",
       "<code>groupBy</code>, <code>groupBy</code>,\n",
       "<code>group_by</code>, <code>group_by</code>;\n",
       "<code>head</code>; <code>insertInto</code>,\n",
       "<code>insertInto</code>; <code>intersect</code>,\n",
       "<code>intersect</code>; <code>isLocal</code>,\n",
       "<code>isLocal</code>; <code>join</code>;\n",
       "<code>limit</code>, <code>limit</code>;\n",
       "<code>merge</code>, <code>merge</code>;\n",
       "<code>mutate</code>, <code>mutate</code>,\n",
       "<code>transform</code>; <code>ncol</code>;\n",
       "<code>persist</code>; <code>printSchema</code>;\n",
       "<code>rbind</code>, <code>rbind</code>,\n",
       "<code>unionAll</code>, <code>unionAll</code>;\n",
       "<code>registerTempTable</code>,\n",
       "<code>registerTempTable</code>; <code>rename</code>,\n",
       "<code>rename</code>, <code>withColumnRenamed</code>,\n",
       "<code>withColumnRenamed</code>;\n",
       "<code>repartition</code>; <code>sample</code>,\n",
       "<code>sample</code>, <code>sample_frac</code>,\n",
       "<code>sample_frac</code>;\n",
       "<code>saveAsParquetFile</code>,\n",
       "<code>saveAsParquetFile</code>,\n",
       "<code>write.parquet</code>, <code>write.parquet</code>;\n",
       "<code>saveAsTable</code>, <code>saveAsTable</code>;\n",
       "<code>saveDF</code>, <code>saveDF</code>,\n",
       "<code>write.df</code>, <code>write.df</code>;\n",
       "<code>selectExpr</code>; <code>showDF</code>,\n",
       "<code>showDF</code>; <code>show</code>,\n",
       "<code>show</code>,\n",
       "<code>show,GroupedData-method</code>;\n",
       "<code>take</code>; <code>transform</code>,\n",
       "<code>withColumn</code>, <code>withColumn</code>;\n",
       "<code>unpersist</code>; <code>write.json</code>,\n",
       "<code>write.json</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "## Not run: \n",
       "sc &lt;- sparkR.init()\n",
       "sqlContext &lt;- sparkRSQL.init(sc)\n",
       "path &lt;- \"path/to/file.json\"\n",
       "df &lt;- read.json(sqlContext, path)\n",
       "describe(df)\n",
       "describe(df, \"col1\")\n",
       "describe(df, \"col1\", \"col2\")\n",
       "\n",
       "## End(Not run)\n",
       "## Not run: \n",
       "model &lt;- glm(y ~ x, trainingData)\n",
       "summary(model)\n",
       "\n",
       "## End(Not run)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>SparkR</em> version 1.6.0 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{describe}{summary}{describe}\n",
       "\\aliasA{summary}{describe}{summary}\n",
       "\\aliasA{summary,PipelineModel-method}{describe}{summary,PipelineModel.Rdash.method}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Computes statistics for numeric columns.\n",
       "If no columns are given, this function computes statistics for all numerical columns.\n",
       "\n",
       "Returns the summary of a model produced by glm(), similarly to R's summary().\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "## S4 method for signature 'DataFrame,character'\n",
       "describe(x, col, ...)\n",
       "\n",
       "## S4 method for signature 'DataFrame,ANY'\n",
       "describe(x)\n",
       "\n",
       "## S4 method for signature 'DataFrame'\n",
       "summary(object, ...)\n",
       "\n",
       "describe(x, col, ...)\n",
       "\n",
       "summary(object, ...)\n",
       "\n",
       "## S4 method for signature 'PipelineModel'\n",
       "summary(object, ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{x}] A DataFrame to be computed.\n",
       "\n",
       "\\item[\\code{col}] A string of name\n",
       "\n",
       "\\item[\\code{...}] Additional expressions\n",
       "\n",
       "\\item[\\code{object}] A fitted MLlib model\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Value}\n",
       "A DataFrame\n",
       "\n",
       "a list with 'devianceResiduals' and 'coefficients' components for gaussian family\n",
       "or a list with 'coefficients' component for binomial family. \\\\{}\n",
       "For gaussian family: the 'devianceResiduals' gives the min/max deviance residuals\n",
       "of the estimation, the 'coefficients' gives the estimated coefficients and their\n",
       "estimated standard errors, t values and p-values. (It only available when model\n",
       "fitted by normal solver.) \\\\{}\n",
       "For binomial family: the 'coefficients' gives the estimated coefficients.\n",
       "See summary.glm for more information. \\\\{}\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "Other DataFrame functions: \\code{\\LinkA{\\$}{.Rdol.}},\n",
       "\\code{\\LinkA{\\$<-}{.Rdol.<.Rdash.}}, \\code{\\LinkA{select}{select}},\n",
       "\\code{\\LinkA{select}{select}},\n",
       "\\code{\\LinkA{select,DataFrame,Column-method}{select,DataFrame,Column.Rdash.method}},\n",
       "\\code{\\LinkA{select,DataFrame,list-method}{select,DataFrame,list.Rdash.method}},\n",
       "\\code{\\LinkA{selectExpr}{selectExpr}}; \\code{\\LinkA{DataFrame-class}{DataFrame.Rdash.class}},\n",
       "\\code{\\LinkA{dataFrame}{dataFrame}}, \\code{\\LinkA{groupedData}{groupedData}};\n",
       "\\code{\\LinkA{[}{[}}, \\code{\\LinkA{[}{[}}, \\code{\\LinkA{[[}{[[}},\n",
       "\\code{\\LinkA{subset}{subset}}; \\code{\\LinkA{agg}{agg}},\n",
       "\\code{\\LinkA{agg}{agg}},\n",
       "\\code{\\LinkA{count,GroupedData-method}{count,GroupedData.Rdash.method}},\n",
       "\\code{\\LinkA{summarize}{summarize}}, \\code{\\LinkA{summarize}{summarize}};\n",
       "\\code{\\LinkA{arrange}{arrange}}, \\code{\\LinkA{arrange}{arrange}},\n",
       "\\code{\\LinkA{arrange}{arrange}}, \\code{\\LinkA{orderBy}{orderBy}},\n",
       "\\code{\\LinkA{orderBy}{orderBy}}; \\code{\\LinkA{as.data.frame}{as.data.frame}},\n",
       "\\code{\\LinkA{as.data.frame,DataFrame-method}{as.data.frame,DataFrame.Rdash.method}};\n",
       "\\code{\\LinkA{attach}{attach}},\n",
       "\\code{\\LinkA{attach,DataFrame-method}{attach,DataFrame.Rdash.method}};\n",
       "\\code{\\LinkA{cache}{cache}}; \\code{\\LinkA{collect}{collect}};\n",
       "\\code{\\LinkA{colnames}{colnames}}, \\code{\\LinkA{colnames}{colnames}},\n",
       "\\code{\\LinkA{colnames<-}{colnames<.Rdash.}}, \\code{\\LinkA{colnames<-}{colnames<.Rdash.}},\n",
       "\\code{\\LinkA{columns}{columns}}, \\code{\\LinkA{names}{names}},\n",
       "\\code{\\LinkA{names<-}{names<.Rdash.}}; \\code{\\LinkA{coltypes}{coltypes}},\n",
       "\\code{\\LinkA{coltypes}{coltypes}}, \\code{\\LinkA{coltypes<-}{coltypes<.Rdash.}},\n",
       "\\code{\\LinkA{coltypes<-}{coltypes<.Rdash.}}; \\code{\\LinkA{columns}{columns}},\n",
       "\\code{\\LinkA{dtypes}{dtypes}}, \\code{\\LinkA{printSchema}{printSchema}},\n",
       "\\code{\\LinkA{schema}{schema}}, \\code{\\LinkA{schema}{schema}};\n",
       "\\code{\\LinkA{count}{count}}, \\code{\\LinkA{nrow}{nrow}};\n",
       "\\code{\\LinkA{dim}{dim}}; \\code{\\LinkA{distinct}{distinct}},\n",
       "\\code{\\LinkA{unique}{unique}}; \\code{\\LinkA{dropna}{dropna}},\n",
       "\\code{\\LinkA{dropna}{dropna}}, \\code{\\LinkA{fillna}{fillna}},\n",
       "\\code{\\LinkA{fillna}{fillna}}, \\code{\\LinkA{na.omit}{na.omit}},\n",
       "\\code{\\LinkA{na.omit}{na.omit}}; \\code{\\LinkA{dtypes}{dtypes}};\n",
       "\\code{\\LinkA{except}{except}}, \\code{\\LinkA{except}{except}};\n",
       "\\code{\\LinkA{explain}{explain}}, \\code{\\LinkA{explain}{explain}};\n",
       "\\code{\\LinkA{filter}{filter}}, \\code{\\LinkA{filter}{filter}},\n",
       "\\code{\\LinkA{where}{where}}, \\code{\\LinkA{where}{where}};\n",
       "\\code{\\LinkA{first}{first}}, \\code{\\LinkA{first}{first}};\n",
       "\\code{\\LinkA{groupBy}{groupBy}}, \\code{\\LinkA{groupBy}{groupBy}},\n",
       "\\code{\\LinkA{group\\_by}{group.Rul.by}}, \\code{\\LinkA{group\\_by}{group.Rul.by}};\n",
       "\\code{\\LinkA{head}{head}}; \\code{\\LinkA{insertInto}{insertInto}},\n",
       "\\code{\\LinkA{insertInto}{insertInto}}; \\code{\\LinkA{intersect}{intersect}},\n",
       "\\code{\\LinkA{intersect}{intersect}}; \\code{\\LinkA{isLocal}{isLocal}},\n",
       "\\code{\\LinkA{isLocal}{isLocal}}; \\code{\\LinkA{join}{join}};\n",
       "\\code{\\LinkA{limit}{limit}}, \\code{\\LinkA{limit}{limit}};\n",
       "\\code{\\LinkA{merge}{merge}}, \\code{\\LinkA{merge}{merge}};\n",
       "\\code{\\LinkA{mutate}{mutate}}, \\code{\\LinkA{mutate}{mutate}},\n",
       "\\code{\\LinkA{transform}{transform}}; \\code{\\LinkA{ncol}{ncol}};\n",
       "\\code{\\LinkA{persist}{persist}}; \\code{\\LinkA{printSchema}{printSchema}};\n",
       "\\code{\\LinkA{rbind}{rbind}}, \\code{\\LinkA{rbind}{rbind}},\n",
       "\\code{\\LinkA{unionAll}{unionAll}}, \\code{\\LinkA{unionAll}{unionAll}};\n",
       "\\code{\\LinkA{registerTempTable}{registerTempTable}},\n",
       "\\code{\\LinkA{registerTempTable}{registerTempTable}}; \\code{\\LinkA{rename}{rename}},\n",
       "\\code{\\LinkA{rename}{rename}}, \\code{\\LinkA{withColumnRenamed}{withColumnRenamed}},\n",
       "\\code{\\LinkA{withColumnRenamed}{withColumnRenamed}};\n",
       "\\code{\\LinkA{repartition}{repartition}}; \\code{\\LinkA{sample}{sample}},\n",
       "\\code{\\LinkA{sample}{sample}}, \\code{\\LinkA{sample\\_frac}{sample.Rul.frac}},\n",
       "\\code{\\LinkA{sample\\_frac}{sample.Rul.frac}};\n",
       "\\code{\\LinkA{saveAsParquetFile}{saveAsParquetFile}},\n",
       "\\code{\\LinkA{saveAsParquetFile}{saveAsParquetFile}},\n",
       "\\code{\\LinkA{write.parquet}{write.parquet}}, \\code{\\LinkA{write.parquet}{write.parquet}};\n",
       "\\code{\\LinkA{saveAsTable}{saveAsTable}}, \\code{\\LinkA{saveAsTable}{saveAsTable}};\n",
       "\\code{\\LinkA{saveDF}{saveDF}}, \\code{\\LinkA{saveDF}{saveDF}},\n",
       "\\code{\\LinkA{write.df}{write.df}}, \\code{\\LinkA{write.df}{write.df}};\n",
       "\\code{\\LinkA{selectExpr}{selectExpr}}; \\code{\\LinkA{showDF}{showDF}},\n",
       "\\code{\\LinkA{showDF}{showDF}}; \\code{\\LinkA{show}{show}},\n",
       "\\code{\\LinkA{show}{show}},\n",
       "\\code{\\LinkA{show,GroupedData-method}{show,GroupedData.Rdash.method}};\n",
       "\\code{\\LinkA{take}{take}}; \\code{\\LinkA{transform}{transform}},\n",
       "\\code{\\LinkA{withColumn}{withColumn}}, \\code{\\LinkA{withColumn}{withColumn}};\n",
       "\\code{\\LinkA{unpersist}{unpersist}}; \\code{\\LinkA{write.json}{write.json}},\n",
       "\\code{\\LinkA{write.json}{write.json}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "## Not run: \n",
       "sc <- sparkR.init()\n",
       "sqlContext <- sparkRSQL.init(sc)\n",
       "path <- \"path/to/file.json\"\n",
       "df <- read.json(sqlContext, path)\n",
       "describe(df)\n",
       "describe(df, \"col1\")\n",
       "describe(df, \"col1\", \"col2\")\n",
       "\n",
       "## End(Not run)\n",
       "## Not run: \n",
       "model <- glm(y ~ x, trainingData)\n",
       "summary(model)\n",
       "\n",
       "## End(Not run)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "describe                package:SparkR                 R Documentation\n",
       "\n",
       "_\bs_\bu_\bm_\bm_\ba_\br_\by\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Computes statistics for numeric columns. If no columns are given,\n",
       "     this function computes statistics for all numerical columns.\n",
       "\n",
       "     Returns the summary of a model produced by glm(), similarly to R's\n",
       "     summary().\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     ## S4 method for signature 'DataFrame,character'\n",
       "     describe(x, col, ...)\n",
       "     \n",
       "     ## S4 method for signature 'DataFrame,ANY'\n",
       "     describe(x)\n",
       "     \n",
       "     ## S4 method for signature 'DataFrame'\n",
       "     summary(object, ...)\n",
       "     \n",
       "     describe(x, col, ...)\n",
       "     \n",
       "     summary(object, ...)\n",
       "     \n",
       "     ## S4 method for signature 'PipelineModel'\n",
       "     summary(object, ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       x: A DataFrame to be computed.\n",
       "\n",
       "     col: A string of name\n",
       "\n",
       "     ...: Additional expressions\n",
       "\n",
       "  object: A fitted MLlib model\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A DataFrame\n",
       "\n",
       "     a list with 'devianceResiduals' and 'coefficients' components for\n",
       "     gaussian family or a list with 'coefficients' component for\n",
       "     binomial family.\n",
       "     For gaussian family: the 'devianceResiduals' gives the min/max\n",
       "     deviance residuals of the estimation, the 'coefficients' gives the\n",
       "     estimated coefficients and their estimated standard errors, t\n",
       "     values and p-values. (It only available when model fitted by\n",
       "     normal solver.)\n",
       "     For binomial family: the 'coefficients' gives the estimated\n",
       "     coefficients.  See summary.glm for more information.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     Other DataFrame functions: ‘$’, ‘$<-’, ‘select’, ‘select’,\n",
       "     ‘select,DataFrame,Column-method’, ‘select,DataFrame,list-method’,\n",
       "     ‘selectExpr’; ‘DataFrame-class’, ‘dataFrame’, ‘groupedData’; ‘[’,\n",
       "     ‘[’, ‘[[’, ‘subset’; ‘agg’, ‘agg’, ‘count,GroupedData-method’,\n",
       "     ‘summarize’, ‘summarize’; ‘arrange’, ‘arrange’, ‘arrange’,\n",
       "     ‘orderBy’, ‘orderBy’; ‘as.data.frame’,\n",
       "     ‘as.data.frame,DataFrame-method’; ‘attach’,\n",
       "     ‘attach,DataFrame-method’; ‘cache’; ‘collect’; ‘colnames’,\n",
       "     ‘colnames’, ‘colnames<-’, ‘colnames<-’, ‘columns’, ‘names’,\n",
       "     ‘names<-’; ‘coltypes’, ‘coltypes’, ‘coltypes<-’, ‘coltypes<-’;\n",
       "     ‘columns’, ‘dtypes’, ‘printSchema’, ‘schema’, ‘schema’; ‘count’,\n",
       "     ‘nrow’; ‘dim’; ‘distinct’, ‘unique’; ‘dropna’, ‘dropna’, ‘fillna’,\n",
       "     ‘fillna’, ‘na.omit’, ‘na.omit’; ‘dtypes’; ‘except’, ‘except’;\n",
       "     ‘explain’, ‘explain’; ‘filter’, ‘filter’, ‘where’, ‘where’;\n",
       "     ‘first’, ‘first’; ‘groupBy’, ‘groupBy’, ‘group_by’, ‘group_by’;\n",
       "     ‘head’; ‘insertInto’, ‘insertInto’; ‘intersect’, ‘intersect’;\n",
       "     ‘isLocal’, ‘isLocal’; ‘join’; ‘limit’, ‘limit’; ‘merge’, ‘merge’;\n",
       "     ‘mutate’, ‘mutate’, ‘transform’; ‘ncol’; ‘persist’; ‘printSchema’;\n",
       "     ‘rbind’, ‘rbind’, ‘unionAll’, ‘unionAll’; ‘registerTempTable’,\n",
       "     ‘registerTempTable’; ‘rename’, ‘rename’, ‘withColumnRenamed’,\n",
       "     ‘withColumnRenamed’; ‘repartition’; ‘sample’, ‘sample’,\n",
       "     ‘sample_frac’, ‘sample_frac’; ‘saveAsParquetFile’,\n",
       "     ‘saveAsParquetFile’, ‘write.parquet’, ‘write.parquet’;\n",
       "     ‘saveAsTable’, ‘saveAsTable’; ‘saveDF’, ‘saveDF’, ‘write.df’,\n",
       "     ‘write.df’; ‘selectExpr’; ‘showDF’, ‘showDF’; ‘show’, ‘show’,\n",
       "     ‘show,GroupedData-method’; ‘take’; ‘transform’, ‘withColumn’,\n",
       "     ‘withColumn’; ‘unpersist’; ‘write.json’, ‘write.json’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ## Not run:\n",
       "     \n",
       "     sc <- sparkR.init()\n",
       "     sqlContext <- sparkRSQL.init(sc)\n",
       "     path <- \"path/to/file.json\"\n",
       "     df <- read.json(sqlContext, path)\n",
       "     describe(df)\n",
       "     describe(df, \"col1\")\n",
       "     describe(df, \"col1\", \"col2\")\n",
       "     ## End(Not run)\n",
       "     \n",
       "     ## Not run:\n",
       "     \n",
       "     model <- glm(y ~ x, trainingData)\n",
       "     summary(model)\n",
       "     ## End(Not run)\n",
       "     "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.132   0.016  18.193 "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.time(\n",
    "    traffic_injuries_dfx_summary <- describe(traffic_injuries_dfx)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal class 'DataFrame' [package \"SparkR\"] with 2 slots\n",
      "  ..@ env:<environment: 0x3823548> \n",
      "  ..@ sdf:Class 'jobj' <environment: 0x3830c88> \n"
     ]
    }
   ],
   "source": [
    "str(traffic_injuries_dfx_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark DataFrame tipini, R daki bildiğimiz data frame yapısına çevirmek istediğimizde *collect* i kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for collect {SparkR}\"><tr><td>collect {SparkR}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Collects all the elements of a Spark DataFrame and coerces them into an R data.frame.</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Collects all the elements of a Spark DataFrame and coerces them into an R data.frame.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "## S4 method for signature 'DataFrame'\n",
       "collect(x, stringsAsFactors = FALSE)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>x</code></td>\n",
       "<td>\n",
       "<p>A SparkSQL DataFrame</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>stringsAsFactors</code></td>\n",
       "<td>\n",
       "<p>(Optional) A logical indicating whether or not string columns\n",
       "should be converted to factors. FALSE by default.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p>Other DataFrame functions: <code>$</code>,\n",
       "<code>$&lt;-</code>, <code>select</code>,\n",
       "<code>select</code>,\n",
       "<code>select,DataFrame,Column-method</code>,\n",
       "<code>select,DataFrame,list-method</code>,\n",
       "<code>selectExpr</code>; <code>DataFrame-class</code>,\n",
       "<code>dataFrame</code>, <code>groupedData</code>;\n",
       "<code>[</code>, <code>[</code>, <code>[[</code>,\n",
       "<code>subset</code>; <code>agg</code>,\n",
       "<code>agg</code>,\n",
       "<code>count,GroupedData-method</code>,\n",
       "<code>summarize</code>, <code>summarize</code>;\n",
       "<code>arrange</code>, <code>arrange</code>,\n",
       "<code>arrange</code>, <code>orderBy</code>,\n",
       "<code>orderBy</code>; <code>as.data.frame</code>,\n",
       "<code>as.data.frame,DataFrame-method</code>;\n",
       "<code>attach</code>,\n",
       "<code>attach,DataFrame-method</code>;\n",
       "<code>cache</code>; <code>colnames</code>,\n",
       "<code>colnames</code>, <code>colnames&lt;-</code>,\n",
       "<code>colnames&lt;-</code>, <code>columns</code>,\n",
       "<code>names</code>, <code>names&lt;-</code>;\n",
       "<code>coltypes</code>, <code>coltypes</code>,\n",
       "<code>coltypes&lt;-</code>, <code>coltypes&lt;-</code>;\n",
       "<code>columns</code>, <code>dtypes</code>,\n",
       "<code>printSchema</code>, <code>schema</code>,\n",
       "<code>schema</code>; <code>count</code>,\n",
       "<code>nrow</code>; <code>describe</code>,\n",
       "<code>describe</code>, <code>describe</code>,\n",
       "<code>summary</code>, <code>summary</code>,\n",
       "<code>summary,PipelineModel-method</code>;\n",
       "<code>dim</code>; <code>distinct</code>,\n",
       "<code>unique</code>; <code>dropna</code>,\n",
       "<code>dropna</code>, <code>fillna</code>,\n",
       "<code>fillna</code>, <code>na.omit</code>,\n",
       "<code>na.omit</code>; <code>dtypes</code>;\n",
       "<code>except</code>, <code>except</code>;\n",
       "<code>explain</code>, <code>explain</code>;\n",
       "<code>filter</code>, <code>filter</code>,\n",
       "<code>where</code>, <code>where</code>;\n",
       "<code>first</code>, <code>first</code>;\n",
       "<code>groupBy</code>, <code>groupBy</code>,\n",
       "<code>group_by</code>, <code>group_by</code>;\n",
       "<code>head</code>; <code>insertInto</code>,\n",
       "<code>insertInto</code>; <code>intersect</code>,\n",
       "<code>intersect</code>; <code>isLocal</code>,\n",
       "<code>isLocal</code>; <code>join</code>;\n",
       "<code>limit</code>, <code>limit</code>;\n",
       "<code>merge</code>, <code>merge</code>;\n",
       "<code>mutate</code>, <code>mutate</code>,\n",
       "<code>transform</code>; <code>ncol</code>;\n",
       "<code>persist</code>; <code>printSchema</code>;\n",
       "<code>rbind</code>, <code>rbind</code>,\n",
       "<code>unionAll</code>, <code>unionAll</code>;\n",
       "<code>registerTempTable</code>,\n",
       "<code>registerTempTable</code>; <code>rename</code>,\n",
       "<code>rename</code>, <code>withColumnRenamed</code>,\n",
       "<code>withColumnRenamed</code>;\n",
       "<code>repartition</code>; <code>sample</code>,\n",
       "<code>sample</code>, <code>sample_frac</code>,\n",
       "<code>sample_frac</code>;\n",
       "<code>saveAsParquetFile</code>,\n",
       "<code>saveAsParquetFile</code>,\n",
       "<code>write.parquet</code>, <code>write.parquet</code>;\n",
       "<code>saveAsTable</code>, <code>saveAsTable</code>;\n",
       "<code>saveDF</code>, <code>saveDF</code>,\n",
       "<code>write.df</code>, <code>write.df</code>;\n",
       "<code>selectExpr</code>; <code>showDF</code>,\n",
       "<code>showDF</code>; <code>show</code>,\n",
       "<code>show</code>,\n",
       "<code>show,GroupedData-method</code>;\n",
       "<code>take</code>; <code>transform</code>,\n",
       "<code>withColumn</code>, <code>withColumn</code>;\n",
       "<code>unpersist</code>; <code>write.json</code>,\n",
       "<code>write.json</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "## Not run: \n",
       "sc &lt;- sparkR.init()\n",
       "sqlContext &lt;- sparkRSQL.init(sc)\n",
       "path &lt;- \"path/to/file.json\"\n",
       "df &lt;- read.json(sqlContext, path)\n",
       "collected &lt;- collect(df)\n",
       "firstName &lt;- collected[[1]]$name\n",
       "\n",
       "## End(Not run)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>SparkR</em> version 1.6.0 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{collect}{Collects all the elements of a Spark DataFrame and coerces them into an R data.frame.}{collect}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Collects all the elements of a Spark DataFrame and coerces them into an R data.frame.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "## S4 method for signature 'DataFrame'\n",
       "collect(x, stringsAsFactors = FALSE)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{x}] A SparkSQL DataFrame\n",
       "\n",
       "\\item[\\code{stringsAsFactors}] (Optional) A logical indicating whether or not string columns\n",
       "should be converted to factors. FALSE by default.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "Other DataFrame functions: \\code{\\LinkA{\\$}{.Rdol.}},\n",
       "\\code{\\LinkA{\\$<-}{.Rdol.<.Rdash.}}, \\code{\\LinkA{select}{select}},\n",
       "\\code{\\LinkA{select}{select}},\n",
       "\\code{\\LinkA{select,DataFrame,Column-method}{select,DataFrame,Column.Rdash.method}},\n",
       "\\code{\\LinkA{select,DataFrame,list-method}{select,DataFrame,list.Rdash.method}},\n",
       "\\code{\\LinkA{selectExpr}{selectExpr}}; \\code{\\LinkA{DataFrame-class}{DataFrame.Rdash.class}},\n",
       "\\code{\\LinkA{dataFrame}{dataFrame}}, \\code{\\LinkA{groupedData}{groupedData}};\n",
       "\\code{\\LinkA{[}{[}}, \\code{\\LinkA{[}{[}}, \\code{\\LinkA{[[}{[[}},\n",
       "\\code{\\LinkA{subset}{subset}}; \\code{\\LinkA{agg}{agg}},\n",
       "\\code{\\LinkA{agg}{agg}},\n",
       "\\code{\\LinkA{count,GroupedData-method}{count,GroupedData.Rdash.method}},\n",
       "\\code{\\LinkA{summarize}{summarize}}, \\code{\\LinkA{summarize}{summarize}};\n",
       "\\code{\\LinkA{arrange}{arrange}}, \\code{\\LinkA{arrange}{arrange}},\n",
       "\\code{\\LinkA{arrange}{arrange}}, \\code{\\LinkA{orderBy}{orderBy}},\n",
       "\\code{\\LinkA{orderBy}{orderBy}}; \\code{\\LinkA{as.data.frame}{as.data.frame}},\n",
       "\\code{\\LinkA{as.data.frame,DataFrame-method}{as.data.frame,DataFrame.Rdash.method}};\n",
       "\\code{\\LinkA{attach}{attach}},\n",
       "\\code{\\LinkA{attach,DataFrame-method}{attach,DataFrame.Rdash.method}};\n",
       "\\code{\\LinkA{cache}{cache}}; \\code{\\LinkA{colnames}{colnames}},\n",
       "\\code{\\LinkA{colnames}{colnames}}, \\code{\\LinkA{colnames<-}{colnames<.Rdash.}},\n",
       "\\code{\\LinkA{colnames<-}{colnames<.Rdash.}}, \\code{\\LinkA{columns}{columns}},\n",
       "\\code{\\LinkA{names}{names}}, \\code{\\LinkA{names<-}{names<.Rdash.}};\n",
       "\\code{\\LinkA{coltypes}{coltypes}}, \\code{\\LinkA{coltypes}{coltypes}},\n",
       "\\code{\\LinkA{coltypes<-}{coltypes<.Rdash.}}, \\code{\\LinkA{coltypes<-}{coltypes<.Rdash.}};\n",
       "\\code{\\LinkA{columns}{columns}}, \\code{\\LinkA{dtypes}{dtypes}},\n",
       "\\code{\\LinkA{printSchema}{printSchema}}, \\code{\\LinkA{schema}{schema}},\n",
       "\\code{\\LinkA{schema}{schema}}; \\code{\\LinkA{count}{count}},\n",
       "\\code{\\LinkA{nrow}{nrow}}; \\code{\\LinkA{describe}{describe}},\n",
       "\\code{\\LinkA{describe}{describe}}, \\code{\\LinkA{describe}{describe}},\n",
       "\\code{\\LinkA{summary}{summary}}, \\code{\\LinkA{summary}{summary}},\n",
       "\\code{\\LinkA{summary,PipelineModel-method}{summary,PipelineModel.Rdash.method}};\n",
       "\\code{\\LinkA{dim}{dim}}; \\code{\\LinkA{distinct}{distinct}},\n",
       "\\code{\\LinkA{unique}{unique}}; \\code{\\LinkA{dropna}{dropna}},\n",
       "\\code{\\LinkA{dropna}{dropna}}, \\code{\\LinkA{fillna}{fillna}},\n",
       "\\code{\\LinkA{fillna}{fillna}}, \\code{\\LinkA{na.omit}{na.omit}},\n",
       "\\code{\\LinkA{na.omit}{na.omit}}; \\code{\\LinkA{dtypes}{dtypes}};\n",
       "\\code{\\LinkA{except}{except}}, \\code{\\LinkA{except}{except}};\n",
       "\\code{\\LinkA{explain}{explain}}, \\code{\\LinkA{explain}{explain}};\n",
       "\\code{\\LinkA{filter}{filter}}, \\code{\\LinkA{filter}{filter}},\n",
       "\\code{\\LinkA{where}{where}}, \\code{\\LinkA{where}{where}};\n",
       "\\code{\\LinkA{first}{first}}, \\code{\\LinkA{first}{first}};\n",
       "\\code{\\LinkA{groupBy}{groupBy}}, \\code{\\LinkA{groupBy}{groupBy}},\n",
       "\\code{\\LinkA{group\\_by}{group.Rul.by}}, \\code{\\LinkA{group\\_by}{group.Rul.by}};\n",
       "\\code{\\LinkA{head}{head}}; \\code{\\LinkA{insertInto}{insertInto}},\n",
       "\\code{\\LinkA{insertInto}{insertInto}}; \\code{\\LinkA{intersect}{intersect}},\n",
       "\\code{\\LinkA{intersect}{intersect}}; \\code{\\LinkA{isLocal}{isLocal}},\n",
       "\\code{\\LinkA{isLocal}{isLocal}}; \\code{\\LinkA{join}{join}};\n",
       "\\code{\\LinkA{limit}{limit}}, \\code{\\LinkA{limit}{limit}};\n",
       "\\code{\\LinkA{merge}{merge}}, \\code{\\LinkA{merge}{merge}};\n",
       "\\code{\\LinkA{mutate}{mutate}}, \\code{\\LinkA{mutate}{mutate}},\n",
       "\\code{\\LinkA{transform}{transform}}; \\code{\\LinkA{ncol}{ncol}};\n",
       "\\code{\\LinkA{persist}{persist}}; \\code{\\LinkA{printSchema}{printSchema}};\n",
       "\\code{\\LinkA{rbind}{rbind}}, \\code{\\LinkA{rbind}{rbind}},\n",
       "\\code{\\LinkA{unionAll}{unionAll}}, \\code{\\LinkA{unionAll}{unionAll}};\n",
       "\\code{\\LinkA{registerTempTable}{registerTempTable}},\n",
       "\\code{\\LinkA{registerTempTable}{registerTempTable}}; \\code{\\LinkA{rename}{rename}},\n",
       "\\code{\\LinkA{rename}{rename}}, \\code{\\LinkA{withColumnRenamed}{withColumnRenamed}},\n",
       "\\code{\\LinkA{withColumnRenamed}{withColumnRenamed}};\n",
       "\\code{\\LinkA{repartition}{repartition}}; \\code{\\LinkA{sample}{sample}},\n",
       "\\code{\\LinkA{sample}{sample}}, \\code{\\LinkA{sample\\_frac}{sample.Rul.frac}},\n",
       "\\code{\\LinkA{sample\\_frac}{sample.Rul.frac}};\n",
       "\\code{\\LinkA{saveAsParquetFile}{saveAsParquetFile}},\n",
       "\\code{\\LinkA{saveAsParquetFile}{saveAsParquetFile}},\n",
       "\\code{\\LinkA{write.parquet}{write.parquet}}, \\code{\\LinkA{write.parquet}{write.parquet}};\n",
       "\\code{\\LinkA{saveAsTable}{saveAsTable}}, \\code{\\LinkA{saveAsTable}{saveAsTable}};\n",
       "\\code{\\LinkA{saveDF}{saveDF}}, \\code{\\LinkA{saveDF}{saveDF}},\n",
       "\\code{\\LinkA{write.df}{write.df}}, \\code{\\LinkA{write.df}{write.df}};\n",
       "\\code{\\LinkA{selectExpr}{selectExpr}}; \\code{\\LinkA{showDF}{showDF}},\n",
       "\\code{\\LinkA{showDF}{showDF}}; \\code{\\LinkA{show}{show}},\n",
       "\\code{\\LinkA{show}{show}},\n",
       "\\code{\\LinkA{show,GroupedData-method}{show,GroupedData.Rdash.method}};\n",
       "\\code{\\LinkA{take}{take}}; \\code{\\LinkA{transform}{transform}},\n",
       "\\code{\\LinkA{withColumn}{withColumn}}, \\code{\\LinkA{withColumn}{withColumn}};\n",
       "\\code{\\LinkA{unpersist}{unpersist}}; \\code{\\LinkA{write.json}{write.json}},\n",
       "\\code{\\LinkA{write.json}{write.json}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "## Not run: \n",
       "sc <- sparkR.init()\n",
       "sqlContext <- sparkRSQL.init(sc)\n",
       "path <- \"path/to/file.json\"\n",
       "df <- read.json(sqlContext, path)\n",
       "collected <- collect(df)\n",
       "firstName <- collected[[1]]$name\n",
       "\n",
       "## End(Not run)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "collect                 package:SparkR                 R Documentation\n",
       "\n",
       "_\bC_\bo_\bl_\bl_\be_\bc_\bt_\bs _\ba_\bl_\bl _\bt_\bh_\be _\be_\bl_\be_\bm_\be_\bn_\bt_\bs _\bo_\bf _\ba _\bS_\bp_\ba_\br_\bk _\bD_\ba_\bt_\ba_\bF_\br_\ba_\bm_\be _\ba_\bn_\bd _\bc_\bo_\be_\br_\bc_\be_\bs _\bt_\bh_\be_\bm _\bi_\bn_\bt_\bo _\ba_\bn\n",
       "_\bR _\bd_\ba_\bt_\ba._\bf_\br_\ba_\bm_\be.\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Collects all the elements of a Spark DataFrame and coerces them\n",
       "     into an R data.frame.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     ## S4 method for signature 'DataFrame'\n",
       "     collect(x, stringsAsFactors = FALSE)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       x: A SparkSQL DataFrame\n",
       "\n",
       "stringsAsFactors: (Optional) A logical indicating whether or not string\n",
       "          columns should be converted to factors. FALSE by default.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     Other DataFrame functions: ‘$’, ‘$<-’, ‘select’, ‘select’,\n",
       "     ‘select,DataFrame,Column-method’, ‘select,DataFrame,list-method’,\n",
       "     ‘selectExpr’; ‘DataFrame-class’, ‘dataFrame’, ‘groupedData’; ‘[’,\n",
       "     ‘[’, ‘[[’, ‘subset’; ‘agg’, ‘agg’, ‘count,GroupedData-method’,\n",
       "     ‘summarize’, ‘summarize’; ‘arrange’, ‘arrange’, ‘arrange’,\n",
       "     ‘orderBy’, ‘orderBy’; ‘as.data.frame’,\n",
       "     ‘as.data.frame,DataFrame-method’; ‘attach’,\n",
       "     ‘attach,DataFrame-method’; ‘cache’; ‘colnames’, ‘colnames’,\n",
       "     ‘colnames<-’, ‘colnames<-’, ‘columns’, ‘names’, ‘names<-’;\n",
       "     ‘coltypes’, ‘coltypes’, ‘coltypes<-’, ‘coltypes<-’; ‘columns’,\n",
       "     ‘dtypes’, ‘printSchema’, ‘schema’, ‘schema’; ‘count’, ‘nrow’;\n",
       "     ‘describe’, ‘describe’, ‘describe’, ‘summary’, ‘summary’,\n",
       "     ‘summary,PipelineModel-method’; ‘dim’; ‘distinct’, ‘unique’;\n",
       "     ‘dropna’, ‘dropna’, ‘fillna’, ‘fillna’, ‘na.omit’, ‘na.omit’;\n",
       "     ‘dtypes’; ‘except’, ‘except’; ‘explain’, ‘explain’; ‘filter’,\n",
       "     ‘filter’, ‘where’, ‘where’; ‘first’, ‘first’; ‘groupBy’,\n",
       "     ‘groupBy’, ‘group_by’, ‘group_by’; ‘head’; ‘insertInto’,\n",
       "     ‘insertInto’; ‘intersect’, ‘intersect’; ‘isLocal’, ‘isLocal’;\n",
       "     ‘join’; ‘limit’, ‘limit’; ‘merge’, ‘merge’; ‘mutate’, ‘mutate’,\n",
       "     ‘transform’; ‘ncol’; ‘persist’; ‘printSchema’; ‘rbind’, ‘rbind’,\n",
       "     ‘unionAll’, ‘unionAll’; ‘registerTempTable’, ‘registerTempTable’;\n",
       "     ‘rename’, ‘rename’, ‘withColumnRenamed’, ‘withColumnRenamed’;\n",
       "     ‘repartition’; ‘sample’, ‘sample’, ‘sample_frac’, ‘sample_frac’;\n",
       "     ‘saveAsParquetFile’, ‘saveAsParquetFile’, ‘write.parquet’,\n",
       "     ‘write.parquet’; ‘saveAsTable’, ‘saveAsTable’; ‘saveDF’, ‘saveDF’,\n",
       "     ‘write.df’, ‘write.df’; ‘selectExpr’; ‘showDF’, ‘showDF’; ‘show’,\n",
       "     ‘show’, ‘show,GroupedData-method’; ‘take’; ‘transform’,\n",
       "     ‘withColumn’, ‘withColumn’; ‘unpersist’; ‘write.json’,\n",
       "     ‘write.json’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ## Not run:\n",
       "     \n",
       "     sc <- sparkR.init()\n",
       "     sqlContext <- sparkRSQL.init(sc)\n",
       "     path <- \"path/to/file.json\"\n",
       "     df <- read.json(sqlContext, path)\n",
       "     collected <- collect(df)\n",
       "     firstName <- collected[[1]]$name\n",
       "     ## End(Not run)\n",
       "     "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunu şöyle anlayabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5 obs. of  34 variables:\n",
      " $ summary        : chr  \"count\" \"mean\" \"stddev\" \"min\" ...\n",
      " $ ind_id         : chr  \"2\" \"753.0\" \"0.0\" \"753\" ...\n",
      " $ ind_definition : chr  \"2\" NA NA \"Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\" ...\n",
      " $ reportyear     : chr  \"2\" \"2003.0\" \"1.4142135623730951\" \"2002\" ...\n",
      " $ race_eth_code  : chr  \"2\" \"9.0\" \"0.0\" \"9\" ...\n",
      " $ race_eth_name  : chr  \"2\" NA NA \"Total\" ...\n",
      " $ geotype        : chr  \"2\" NA NA \"CA\" ...\n",
      " $ geotypevalue   : chr  \"2\" \"6.0\" \"0.0\" \"6\" ...\n",
      " $ geoname        : chr  \"2\" NA NA \"California\" ...\n",
      " $ county_name    : chr  \"2\" NA NA \"\" ...\n",
      " $ county_fips    : chr  \"0\" NA NA NA ...\n",
      " $ region_name    : chr  \"2\" NA NA \"\" ...\n",
      " $ region_code    : chr  \"0\" NA NA NA ...\n",
      " $ mode           : chr  \"2\" NA NA \"All modes\" ...\n",
      " $ severity       : chr  \"2\" NA NA \"Severe Injury\" ...\n",
      " $ injuries       : chr  \"2\" \"13510.5\" \"95.45941546018392\" \"13443.0\" ...\n",
      " $ totalpop       : chr  \"2\" \"3.53322865E7\" \"548323.8321507648\" \"3.4944563E7\" ...\n",
      " $ poprate        : chr  \"2\" \"38.2409056063083\" \"0.32328670155405215\" \"38.012307387372\" ...\n",
      " $ LL95CI_poprate : chr  \"2\" \"37.59605504897385\" \"0.3155571492957887\" \"37.3729224488549\" ...\n",
      " $ UL95CI_poprate : chr  \"2\" \"38.8857561636427\" \"0.33101625381223515\" \"38.6516923258891\" ...\n",
      " $ poprate_se     : chr  \"2\" \"0.3290053863951155\" \"0.00394364911133956\" \"0.326216805365867\" ...\n",
      " $ poprate_rse    : chr  \"2\" \"0.8603365118699515\" \"0.003039403909039202\" \"0.858187328755105\" ...\n",
      " $ CA_decile_pop  : chr  \"2\" NA NA \"\" ...\n",
      " $ CA_RR_poprate  : chr  \"2\" \"1.0\" \"0.0\" \"1.0\" ...\n",
      " $ avmttotal      : chr  \"2\" \"3.3038006678046497E11\" \"5.002993520756106E9\" \"3.26842416135706E11\" ...\n",
      " $ avmtrate       : chr  \"2\" \"40.8963123221578\" \"0.33036063941136157\" \"40.6627120737929\" ...\n",
      " $ LL95CI_avmtrate: chr  \"2\" \"40.20668450442835\" \"0.32235361346989605\" \"39.9787460784038\" ...\n",
      " $ UL95CI_avmtrate: chr  \"2\" \"41.5859401398873\" \"0.33836766535290747\" \"41.346678069182\" ...\n",
      " $ avmtrate_se    : chr  \"2\" \"0.35185092741298796\" \"0.004085217317075781\" \"0.348962242545463\" ...\n",
      " $ avmtrate_rse   : chr  \"2\" \"0.8603365118699515\" \"0.003039403909039202\" \"0.858187328755105\" ...\n",
      " $ CA_decile_avmt : chr  \"2\" NA NA \"\" ...\n",
      " $ CA_RR_avmtrate : chr  \"2\" \"1.0\" \"0.0\" \"1.0\" ...\n",
      " $ groupquarters  : chr  \"2\" \"823906.0\" \"1067.7312395916867\" \"823151.0\" ...\n",
      " $ version        : chr  \"2\" NA NA \"10/10/2014 12:00:00 AM\" ...\n"
     ]
    }
   ],
   "source": [
    "str(collect(traffic_injuries_dfx_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu tanıdık geldi. R daki data.frame! Bu yapıda R komutlarını rahatlıkla kullanabiliriz. DataFrame nesnesinde olduğumuzda sadece SparkR ile bize verilen fonksiyonları kullanabiliyoruz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>summary</th><th scope=col>ind_id</th><th scope=col>ind_definition</th><th scope=col>reportyear</th><th scope=col>race_eth_code</th><th scope=col>race_eth_name</th><th scope=col>geotype</th><th scope=col>geotypevalue</th><th scope=col>geoname</th><th scope=col>county_name</th><th scope=col>ellip.h</th><th scope=col>avmttotal</th><th scope=col>avmtrate</th><th scope=col>LL95CI_avmtrate</th><th scope=col>UL95CI_avmtrate</th><th scope=col>avmtrate_se</th><th scope=col>avmtrate_rse</th><th scope=col>CA_decile_avmt</th><th scope=col>CA_RR_avmtrate</th><th scope=col>groupquarters</th><th scope=col>version</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>count</td><td>494226</td><td>494226</td><td>494226</td><td>494226</td><td>494226</td><td>494226</td><td>494226</td><td>494226</td><td>494226</td><td>⋯</td><td>12320</td><td>11774</td><td>11774</td><td>11774</td><td>11774</td><td>11774</td><td>494226</td><td>11774</td><td>59418</td><td>494226</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>mean</td><td>753.0</td><td>NA</td><td>2005.8811921576626</td><td>9.0</td><td>NA</td><td>NA</td><td>4.431001576189009E9</td><td>1847.7611721738963</td><td>NA</td><td>⋯</td><td>3.03027658757078E9</td><td>63.906113027811585</td><td>20.57549144469093</td><td>122.50280012022058</td><td>29.896268924698862</td><td>52.30289196387992</td><td>5.50058207217695</td><td>2.658148755860837</td><td>9092.740300918913</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>stddev</td><td>0.0</td><td>NA</td><td>2.5442331668765643</td><td>0.0</td><td>NA</td><td>NA</td><td>3.256269125340502E9</td><td>2376.7218177940317</td><td>NA</td><td>⋯</td><td>2.310023852979673E10</td><td>130.3678309097662</td><td>57.25034022249537</td><td>290.4571520031402</td><td>89.09777729450262</td><td>39.04897780494879</td><td>2.8690840032038887</td><td>5.41543275468215</td><td>49322.98790573563</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>min</td><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2002</td><td>9</td><td>Total</td><td>CA</td><td>1</td><td>0001.00</td><td></td><td>⋯</td><td>0.0</td><td>0.674050088276818</td><td>0.0</td><td>1.60823584930548</td><td>0.136645672215764</td><td>0.858187328755105</td><td></td><td>0.091088010318861</td><td>0.0</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>max</td><td>753</td><td>Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode</td><td>2010</td><td>9</td><td>Total</td><td>RE</td><td>99999999999</td><td>Zayante CDP</td><td>Yuba</td><td>⋯</td><td>3.36306148012608E11</td><td>4949.82133549228</td><td>770.840342077224</td><td>11809.9237101896</td><td>3500.05223198844</td><td>223.606797749979</td><td>9</td><td>246.054811599176</td><td>834673.0</td><td>10/10/2014 12:00:00 AM</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllll}\n",
       "  & summary & ind_id & ind_definition & reportyear & race_eth_code & race_eth_name & geotype & geotypevalue & geoname & county_name & ellip.h & avmttotal & avmtrate & LL95CI_avmtrate & UL95CI_avmtrate & avmtrate_se & avmtrate_rse & CA_decile_avmt & CA_RR_avmtrate & groupquarters & version\\\\\n",
       "\\hline\n",
       "\t1 & count & 494226 & 494226 & 494226 & 494226 & 494226 & 494226 & 494226 & 494226 & 494226 & ⋯ & 12320 & 11774 & 11774 & 11774 & 11774 & 11774 & 494226 & 11774 & 59418 & 494226\\\\\n",
       "\t2 & mean & 753.0 & NA & 2005.8811921576626 & 9.0 & NA & NA & 4.431001576189009E9 & 1847.7611721738963 & NA & ⋯ & 3.03027658757078E9 & 63.906113027811585 & 20.57549144469093 & 122.50280012022058 & 29.896268924698862 & 52.30289196387992 & 5.50058207217695 & 2.658148755860837 & 9092.740300918913 & NA\\\\\n",
       "\t3 & stddev & 0.0 & NA & 2.5442331668765643 & 0.0 & NA & NA & 3.256269125340502E9 & 2376.7218177940317 & NA & ⋯ & 2.310023852979673E10 & 130.3678309097662 & 57.25034022249537 & 290.4571520031402 & 89.09777729450262 & 39.04897780494879 & 2.8690840032038887 & 5.41543275468215 & 49322.98790573563 & NA\\\\\n",
       "\t4 & min & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2002 & 9 & Total & CA & 1 & 0001.00 &  & ⋯ & 0.0 & 0.674050088276818 & 0.0 & 1.60823584930548 & 0.136645672215764 & 0.858187328755105 &  & 0.091088010318861 & 0.0 & 10/10/2014 12:00:00 AM\\\\\n",
       "\t5 & max & 753 & Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode & 2010 & 9 & Total & RE & 99999999999 & Zayante CDP & Yuba & ⋯ & 3.36306148012608E11 & 4949.82133549228 & 770.840342077224 & 11809.9237101896 & 3500.05223198844 & 223.606797749979 & 9 & 246.054811599176 & 834673.0 & 10/10/2014 12:00:00 AM\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  summary ind_id\n",
       "1   count 494226\n",
       "2    mean  753.0\n",
       "3  stddev    0.0\n",
       "4     min    753\n",
       "5     max    753\n",
       "                                                                                                   ind_definition\n",
       "1                                                                                                          494226\n",
       "2                                                                                                            <NA>\n",
       "3                                                                                                            <NA>\n",
       "4 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "5 Annual number of fatal and severe road traffic injuries per population and per miles traveled by transport mode\n",
       "          reportyear race_eth_code race_eth_name geotype        geotypevalue\n",
       "1             494226        494226        494226  494226              494226\n",
       "2 2005.8811921576626           9.0          <NA>    <NA> 4.431001576189009E9\n",
       "3 2.5442331668765643           0.0          <NA>    <NA> 3.256269125340502E9\n",
       "4               2002             9         Total      CA                   1\n",
       "5               2010             9         Total      RE         99999999999\n",
       "             geoname county_name        county_fips         region_name\n",
       "1             494226      494226             490649              494226\n",
       "2 1847.7611721738963        <NA>  6056.127857185075                <NA>\n",
       "3 2376.7218177940317        <NA> 27.749560887400015                <NA>\n",
       "4            0001.00                           6001                    \n",
       "5        Zayante CDP        Yuba               6115 Southern California\n",
       "        region_code      mode      severity           injuries\n",
       "1            139344    494226        494226             492843\n",
       "2 8.621368699046963      <NA>          <NA>  7.278504642518813\n",
       "3 4.756852029931538      <NA>          <NA> 117.60155103964075\n",
       "4                 1 All modes        Killed                0.2\n",
       "5                14  Vehicles Severe Injury            13578.0\n",
       "            totalpop            poprate     LL95CI_poprate    UL95CI_poprate\n",
       "1             117669             115979             115979            115979\n",
       "2 247752.11490010843 28.049311734522124  4.181417507785397 72.31163746846656\n",
       "3 1834728.9798289307  240.3873147275784 43.320239498892974 727.2245279334367\n",
       "4                0.0  0.004796806765417                0.0 0.016454008794112\n",
       "5        3.7253956E7            26000.0   4368.36447660526  84784.3525333333\n",
       "          poprate_se        poprate_rse      CA_decile_pop      CA_RR_poprate\n",
       "1             115979             115979             494226             115979\n",
       "2  22.58281925201244 108.56537610764973  5.501333048949557 3.7271379258981017\n",
       "3 257.08639595159747  69.84942157058846 2.8693135137515284 36.876111693591774\n",
       "4  0.005558786754768  0.858187328755105                     0.029064370418436\n",
       "5   29992.0165986394   254.032186026357                  9   5182.95132394366\n",
       "             avmttotal           avmtrate   LL95CI_avmtrate    UL95CI_avmtrate\n",
       "1                12320              11774             11774              11774\n",
       "2   3.03027658757078E9 63.906113027811585 20.57549144469093 122.50280012022058\n",
       "3 2.310023852979673E10  130.3678309097662 57.25034022249537  290.4571520031402\n",
       "4                  0.0  0.674050088276818               0.0   1.60823584930548\n",
       "5  3.36306148012608E11   4949.82133549228  770.840342077224   11809.9237101896\n",
       "         avmtrate_se      avmtrate_rse     CA_decile_avmt    CA_RR_avmtrate\n",
       "1              11774             11774             494226             11774\n",
       "2 29.896268924698862 52.30289196387992   5.50058207217695 2.658148755860837\n",
       "3  89.09777729450262 39.04897780494879 2.8690840032038887  5.41543275468215\n",
       "4  0.136645672215764 0.858187328755105                    0.091088010318861\n",
       "5   3500.05223198844  223.606797749979                  9  246.054811599176\n",
       "      groupquarters                version\n",
       "1             59418                 494226\n",
       "2 9092.740300918913                   <NA>\n",
       "3 49322.98790573563                   <NA>\n",
       "4               0.0 10/10/2014 12:00:00 AM\n",
       "5          834673.0 10/10/2014 12:00:00 AM"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(traffic_injuries_dfx_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabii burada sadece istatistik olarak anlamlı olan kolonları dikkate almak gerekir. Örnek olarak \n",
    "- injuries : yaralanma sayısı\n",
    "- poprate : Toplam nufüs içinde yaralanma oranı (Her 100,000 insan için)\n",
    "\n",
    "alırsak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>summary</th><th scope=col>injuries</th><th scope=col>poprate</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>count</td><td>2</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>mean</td><td>13510.5</td><td>38.2409056063083</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>stddev</td><td>95.45941546018392</td><td>0.32328670155405215</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>min</td><td>13443.0</td><td>38.012307387372</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>max</td><td>13578.0</td><td>38.4695038252446</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & summary & injuries & poprate\\\\\n",
       "\\hline\n",
       "\t1 & count & 2 & 2\\\\\n",
       "\t2 & mean & 13510.5 & 38.2409056063083\\\\\n",
       "\t3 & stddev & 95.45941546018392 & 0.32328670155405215\\\\\n",
       "\t4 & min & 13443.0 & 38.012307387372\\\\\n",
       "\t5 & max & 13578.0 & 38.4695038252446\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  summary          injuries             poprate\n",
       "1   count                 2                   2\n",
       "2    mean           13510.5    38.2409056063083\n",
       "3  stddev 95.45941546018392 0.32328670155405215\n",
       "4     min           13443.0     38.012307387372\n",
       "5     max           13578.0    38.4695038252446"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(select(traffic_injuries_dfx_summary,\"summary\",\"injuries\", \"poprate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu notebook un sonuna geldik. Neler yaptık, \n",
    "- CSV formatlı bir veriyi SparkR kullanarak SparkSQL dataFrame ine aktardık. \n",
    "- Veride bazı tip düzenlemelerin gerektiğini gördük, birini düzelttik. \n",
    "- Kolon bazında özet istatistiklerini aldık. \n",
    "- SparkSQL deki DataFrame ile R deki data.frame arasında operasyon açısından nasıl bir fark olduğuna değindik.\n",
    "\n",
    "[Sonraki notebook](https://github.com/vezir/spark-r-notebooks/blob/master/notebooks/3-dataFrameOperations/dataFrameOperations.ipynb) da biraz daha detaylı işlemler yapacağız."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
